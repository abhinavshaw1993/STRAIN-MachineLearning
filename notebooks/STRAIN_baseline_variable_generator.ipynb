{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from IPython.display import display\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "def generate_baseline_variables(feature_list=[\n",
    "    \"activity_details\",\n",
    "    # \"dinning_details\" ,\n",
    "    \"sms_details\",\n",
    "    \"audio_details\",\n",
    "    \"conversation_details\",\n",
    "    \"dark_details\",\n",
    "    \"phonecharge_details\",\n",
    "    \"phonelock_details\",\n",
    "    \"gps_details\"],\n",
    "    val_set_size = .3,\n",
    "    restrict_seqlen=10,\n",
    "    is_cuda_available=False\n",
    "                               \n",
    "                               ):\n",
    "    \n",
    "    # Dict Initialization.\n",
    "    train_feature_dict = {}\n",
    "    val_feature_dict = {}\n",
    "    train_x_list = []\n",
    "    val_x_list = []\n",
    "    for feature in feature_list:\n",
    "\n",
    "        # Read CSV and skip the time columns.\n",
    "        raw_feature_train_x = pd.read_csv(\"Data/\"+feature+\"_train_x.csv\", skip_blank_lines=False).iloc[:,1:]\n",
    "        raw_feature_train_y = pd.read_csv(\"Data/\"+feature+\"_train_y.csv\", skip_blank_lines=False)\n",
    "        # to bring the values from 0-4.\n",
    "        raw_feature_train_y[\"stress_level\"] += -1\n",
    "        raw_feature_train_y_indices = pd.read_csv(\"Data/\"+feature+\"_train_y_indices.csv\", skip_blank_lines=False)\n",
    "\n",
    "        # Finding Last Valid index.\n",
    "        last_valid_index = raw_feature_train_y_indices.iloc[-1,:].values\n",
    "        last_valid_index = int(last_valid_index)\n",
    "\n",
    "        #Truncating the raw_x features for which y values do not exist.\n",
    "        raw_feature_train_x = raw_feature_train_x.iloc[:last_valid_index+1,:]\n",
    "\n",
    "        # Hardcore indexing, to convert single index to multi so that max, min and avg can be taken easily.\n",
    "        # Train set.\n",
    "        list_a = []\n",
    "        list_b = raw_feature_train_x.index.values    \n",
    "        feature_indices_list = raw_feature_train_y_indices['indices'].values\n",
    "\n",
    "        for idx in feature_indices_list:\n",
    "            if len(list_a) == 0:\n",
    "                list_a += [idx for k in range(0,idx+1)]\n",
    "            else:\n",
    "                list_a += [idx for k in range(len(list_a)-1,idx)]\n",
    "\n",
    "\n",
    "        index_keys = [\n",
    "            np.array(list_a),\n",
    "            np.array(list_b)        \n",
    "        ]\n",
    "\n",
    "\n",
    "        raw_feature_train_x.set_index(keys=index_keys, inplace=True)\n",
    "\n",
    "        # Colapsing Multindex to fin min, max and mean of the seq. \n",
    "        raw_feature_train_x_min = raw_feature_train_x.min(level=0)\n",
    "        raw_feature_train_x_max = raw_feature_train_x.max(level=0)\n",
    "        raw_feature_train_x_mean = raw_feature_train_x.mean(level=0)\n",
    "\n",
    "        raw_feature_train_x = pd.concat([raw_feature_train_x_min, \n",
    "                                         raw_feature_train_x_max.iloc[:,1:], \n",
    "                                         raw_feature_train_x_mean.iloc[:,1:]],\n",
    "                                         axis=1,\n",
    "                                         ignore_index=True)\n",
    "\n",
    "\n",
    "        # splitting data into test and train splits. Keeping 30% of labels for Val.\n",
    "        total_y_labels = len(raw_feature_train_y_indices)\n",
    "        val_samples = total_y_labels * val_set_size\n",
    "        val_samples = math.floor(val_samples)\n",
    "\n",
    "\n",
    "        # Selecting new subset of data.\n",
    "        feature_train_x = raw_feature_train_x.iloc[:total_y_labels-val_samples+1]\n",
    "        feature_train_y = raw_feature_train_y.dropna().iloc[:total_y_labels-val_samples+1]\n",
    "#         print(\"train_x_len\", len(feature_train_x))\n",
    "#         print(\"train_y_len\", len(feature_train_y))\n",
    "\n",
    "        feature_val_x = raw_feature_train_x.iloc[total_y_labels-val_samples+1:]\n",
    "        feature_val_y = raw_feature_train_y.dropna().iloc[total_y_labels-val_samples+1:]\n",
    "        \n",
    "#         print(\"val_x_len\", len(feature_val_x))\n",
    "#         print(\"val_y_len\", len(feature_val_y))\n",
    "        \n",
    "        train_x_list.append(feature_train_x)\n",
    "        val_x_list.append(feature_val_x)\n",
    "    \n",
    "    \n",
    "    # removing extra student_id columns.\n",
    "    # train\n",
    "    first_feature = train_x_list[0]\n",
    "    student_id_col = first_feature.iloc[:,0]\n",
    "    final_list = [feature.iloc[:,1:]  for feature in train_x_list]\n",
    "    final_list.insert(0, student_id_col)\n",
    "    \n",
    "    #resetting indices for each feature.\n",
    "    for i in range(len(final_list)):\n",
    "        final_list[i].reset_index(drop=True, inplace=True)\n",
    "        \n",
    "    train_x = pd.concat(final_list, axis=1, ignore_index=True)\n",
    "    \n",
    "    # val\n",
    "    first_feature = val_x_list[0]\n",
    "    student_id_col = first_feature.iloc[:,0]\n",
    "    final_list =  [ feature.iloc[:,1:]  for feature in val_x_list]\n",
    "    final_list.insert(0, student_id_col)\n",
    "    \n",
    "    #resetting indices for each feature.\n",
    "    for i in range(len(final_list)):\n",
    "        final_list[i].reset_index(drop=True, inplace=True)\n",
    "        \n",
    "    val_x = pd.concat(final_list, axis=1, ignore_index=True)\n",
    "    \n",
    "    train_target = feature_train_y\n",
    "    val_target = feature_val_y\n",
    "    \n",
    "    np_train_x = train_x.as_matrix()\n",
    "    np_val_x = val_x.as_matrix()\n",
    "    np_train_target = train_target.as_matrix()\n",
    "    np_val_target = val_target.as_matrix()\n",
    "    \n",
    "    tensor_train_x = torch.from_numpy(np_train_x)\n",
    "    tensor_val_x = torch.from_numpy(np_val_x) \n",
    "    tensor_train_target = torch.from_numpy(np_train_target)\n",
    "    tensor_val_target = torch.from_numpy(np_val_target)\n",
    "    \n",
    "    if is_cuda_available:\n",
    "        tensor_train_x = tensor_train_x.cuda()\n",
    "        tensor_val_x = tensor_val_x.cuda()\n",
    "        tensor_train_target = tensor_train_target.cuda()\n",
    "        tensor_val_target = tensor_val_target.cuda()\n",
    "\n",
    "    train_input_seq = Variable(tensor_train_x ,requires_grad=False).float()\n",
    "    train_target = Variable(tensor_train_target ,requires_grad=False).long()\n",
    "    val_input_seq = Variable(tensor_val_x ,requires_grad=False).float()\n",
    "    val_target = Variable(tensor_val_target ,requires_grad=False).long()\n",
    "    \n",
    "    return train_input_seq, train_target, val_input_seq, val_target\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "\n",
       "Columns 0 to 7 \n",
       "   1.0000    0.0000    0.0000    0.0000    1.0000    1.0000    1.0000    6.0000\n",
       "   1.0000    0.0000    0.0000    0.0000    1.0000    1.0000    1.0000    6.0000\n",
       "   1.0000    0.0000    0.0000    0.0000    1.0000    1.0000    1.0000    6.0000\n",
       "   1.0000    0.0000    0.0000    0.0000    1.0000    1.0000    1.0000    6.0000\n",
       "   1.0000    0.0000    3.0000    0.0120    1.0000    1.0000    1.0000    6.0000\n",
       "   1.0000    0.0000    3.0000    0.1290    1.0000    1.0000    1.0000    0.0000\n",
       "   1.0000    0.0000    3.0000    0.2176    1.0000    1.0000    1.0000    1.0000\n",
       "   1.0000    0.0000    3.0000    0.2407    1.0000    1.0000    1.0000    1.0000\n",
       "   1.0000    0.0000    3.0000    0.1120    1.0000    1.0000    1.0000    1.0000\n",
       "   1.0000    0.0000    3.0000    0.0306    1.0000    1.0000    1.0000    1.0000\n",
       "   1.0000    0.0000    3.0000    0.1028    1.0000    1.0000    1.0000    1.0000\n",
       "   1.0000    0.0000    3.0000    0.1356    1.0000    1.0000    1.0000    0.0000\n",
       "   1.0000    0.0000    3.0000    0.1108    1.0000    1.0000    1.0000    1.0000\n",
       "   1.0000    0.0000    3.0000    0.1737    1.0000    1.0000    1.0000    1.0000\n",
       "   1.0000    0.0000    3.0000    0.1402    1.0000    1.0000    1.0000    0.0000\n",
       "   1.0000    0.0000    3.0000    0.1035    1.0000    1.0000    1.0000    1.0000\n",
       "   1.0000    0.0000    3.0000    0.1098    1.0000    1.0000    1.0000    0.0000\n",
       "   1.0000    0.0000    3.0000    0.1633    1.0000    1.0000    1.0000    0.0000\n",
       "   1.0000    0.0000    3.0000    0.0547    1.0000    1.0000    1.0000    1.0000\n",
       "   1.0000    0.0000    3.0000    0.0876    1.0000    1.0000    1.0000    1.0000\n",
       "   1.0000    0.0000    3.0000    0.0422    1.0000    1.0000    1.0000    1.0000\n",
       "   1.0000    0.0000    3.0000    0.0851    1.0000    1.0000    1.0000    0.0000\n",
       "   1.0000    0.0000    3.0000    0.1346    1.0000    1.0000    1.0000    0.0000\n",
       "   1.0000    0.0000    3.0000    0.0460    1.0000    1.0000    1.0000    0.0000\n",
       "   1.0000    0.0000    3.0000    0.0923    1.0000    1.0000    1.0000    1.0000\n",
       "   1.0000    0.0000    3.0000    0.0323    1.0000    1.0000    1.0000    1.0000\n",
       "   1.0000    0.0000    3.0000    0.0743    1.0000    1.0000    1.0000    1.0000\n",
       "\n",
       "Columns 8 to 9 \n",
       "   6.0000    6.0000\n",
       "   6.0000    6.0000\n",
       "   6.0000    6.0000\n",
       "   6.0000    6.0000\n",
       "   6.0000    6.0000\n",
       "  54.0000   11.5918\n",
       "  74.0000   13.5294\n",
       "  51.0000   15.0714\n",
       " 123.0000   16.7600\n",
       "  55.0000   11.7727\n",
       "  60.0000    8.5926\n",
       "  68.0000    8.6905\n",
       " 169.0000   28.1935\n",
       "  66.0000   14.1538\n",
       "  97.0000   14.1515\n",
       "  83.0000   18.0000\n",
       "  99.0000   14.0870\n",
       "  86.0000   14.0143\n",
       " 114.0000   13.0357\n",
       "  75.0000   20.6667\n",
       "  35.0000    9.0714\n",
       " 100.0000   14.6757\n",
       " 116.0000   18.2344\n",
       "  51.0000   14.0667\n",
       "  54.0000   10.5094\n",
       "  51.0000   11.8667\n",
       "  36.0000    9.3810\n",
       "[torch.FloatTensor of size 27x10]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "    0\n",
       "    2\n",
       "    3\n",
       "    2\n",
       "    3\n",
       "    3\n",
       "    0\n",
       "    4\n",
       "    0\n",
       "    0\n",
       "    1\n",
       "    0\n",
       "    3\n",
       "    3\n",
       "    3\n",
       "    4\n",
       "    0\n",
       "    0\n",
       "    1\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    3\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "[torch.LongTensor of size 27x1]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "\n",
       "Columns 0 to 7 \n",
       "   1.0000    0.0000    3.0000    0.1767    1.0000    1.0000    1.0000    1.0000\n",
       "   1.0000    0.0000    3.0000    0.1507    1.0000    1.0000    1.0000    0.0000\n",
       "   1.0000    0.0000    3.0000    0.1012    1.0000    1.0000    1.0000    0.0000\n",
       "   1.0000    0.0000    3.0000    0.2496    1.0000    1.0000    1.0000    0.0000\n",
       "   1.0000    0.0000    3.0000    0.0305    1.0000    1.0000    1.0000    1.0000\n",
       "   1.0000    0.0000    0.0000    0.0000    1.0000    1.0000    1.0000   22.0000\n",
       "   1.0000    0.0000    3.0000    0.0085    1.0000    1.0000    1.0000    1.0000\n",
       "   1.0000    0.0000    3.0000    0.0988    1.0000    1.0000    1.0000   18.0000\n",
       "   1.0000    0.0000    3.0000    0.1110    1.0000    1.0000    1.0000    0.0000\n",
       "\n",
       "Columns 8 to 9 \n",
       "  78.0000   14.3049\n",
       " 108.0000   11.7541\n",
       " 102.0000    9.5182\n",
       "  58.0000    7.8992\n",
       "  51.0000   17.1818\n",
       "  66.0000   36.6667\n",
       "  26.0000   15.2727\n",
       "  18.0000   18.0000\n",
       " 109.0000   10.8681\n",
       "[torch.FloatTensor of size 9x10]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "    3\n",
       "    3\n",
       "    0\n",
       "    1\n",
       "    1\n",
       "    1\n",
       "    2\n",
       "    1\n",
       "    0\n",
       "[torch.LongTensor of size 9x1]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_list=[\"activity_details\",\n",
    "             \"sms_details\",\n",
    "    \"conversation_details\",\n",
    "             ]\n",
    "train_input_seq, train_target, val_input_seq, val_target = generate_baseline_variables(feature_list)\n",
    "\n",
    "display(train_input_seq)\n",
    "display(train_target)\n",
    "display(val_input_seq)\n",
    "display(val_target)\n",
    "\n",
    "\n",
    "# print(train_input_seq.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
