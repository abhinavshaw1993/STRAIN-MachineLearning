{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "\n",
    "# Create a connection with SQL server to get data.\n",
    "def exec_sql_query(query, param=None):\n",
    "    \n",
    "    from sqlalchemy import create_engine\n",
    "    import urllib\n",
    "    params = urllib.parse.quote_plus(\"DRIVER={SQL Server Native Client 11.0};SERVER=LAPTOP-C3LFVOFI;DATABASE=student_life;UID=student_sense;PWD=abhinav123\")\n",
    "    engine = create_engine(\"mssql+pyodbc:///?odbc_connect=%s\" % params)\n",
    "    connection = engine.raw_connection()\n",
    "    \n",
    "    try:\n",
    "        cursor = connection.cursor()\n",
    "        if(param):\n",
    "            cursor.execute(query, param)\n",
    "        else : \n",
    "            cursor.execute(query)\n",
    "            \n",
    "        results = cursor.fetchall()\n",
    "        columns = [column[0] for column in cursor.description]\n",
    "        df = pd.DataFrame.from_records(results, columns=columns)\n",
    "        cursor.close()\n",
    "        connection.commit()\n",
    "    finally:\n",
    "        connection.close()\n",
    "    \n",
    "    del engine\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Maintaining a feature list.\n",
    "feature_map = {\n",
    "\n",
    "#     \"activity_details\" : \"SELECT activity_time ,student_id ,activity_inference FROM activity_details where student_id = 1\"\n",
    "    \n",
    "    \"dinning_details\" : \"SELECT dinning_time ,student_id ,venue_id ,meal_type_id FROM dinning_details where student_id = 1\",\n",
    "    \n",
    "#     \"call_log_details\" : \"select call_time, student_id, call_duration_min, call_type from call_log_details where student_id = 1\",\n",
    "    \n",
    "    \"sms_details\" : \"select timestamp, student_id, 1 from sms_details where student_id = 1\",\n",
    "    \n",
    "    \"audio_details\" : \"select audio_activity_time, student_id, audio_activity_inference from audio_details where student_id = 1\",\n",
    "    \n",
    "    \"conversation_details\" : \"select conv_start_timestamp, student_id, conv_duration_min from conversation_details where student_id = 1\",\n",
    "    \n",
    "    \"dark_details\" : \"select dark_start_timestamp, student_id, dark_duration_min from dark_details where student_id = 1\",\n",
    "    \n",
    "    \"phonecharge_details\" : \"select start_timestamp, student_id, phonecharge_duration_min from phonecharge_details where student_id = 1\",\n",
    "\n",
    "    \"phonelock_details\" : \"select start_timestamp, student_id, phonelock_duration_min from phonelock_details where student_id = 1\",\n",
    "     \n",
    "    \"gps_details\" : \"select wifi_timestamp as time, student_id, latitude, longitude from gps_details where student_id = 1\"\n",
    "    \n",
    "                         }\n",
    "\n",
    "# Getting Raw Data.\n",
    "\n",
    "data_dict = {}\n",
    "\n",
    "# Processing Stress Levels.\n",
    "stress_details_raw = exec_sql_query(\"select student_id, response_time, stress_level from stress_details where student_id = 1\")\n",
    "stress_details = stress_details_raw.loc[:,[\"response_time\",\"student_id\",\"stress_level\"]]\n",
    "stress_details = stress_details.sort_values(by=\"response_time\")\n",
    "stress_details.rename({\"response_time\": \"time\"}, axis='columns', inplace=True)\n",
    "\n",
    "for key in query_map.keys():\n",
    "    \n",
    "    feature_query = query_map[key]\n",
    "    \n",
    "    # Data processing begins..\n",
    "    feature_data = exec_sql_query(feature_query)\n",
    "    \n",
    "    \n",
    "    # Selecting Time Col.\n",
    "    train_col_list = []\n",
    "    \n",
    "    for col in feature_data.columns:\n",
    "        if \"time\" in col:\n",
    "            time_column = col\n",
    "        else:\n",
    "            train_col_list.append(col)\n",
    "    \n",
    "    feature_data.rename({time_column: \"time\"}, axis='columns', inplace=True)\n",
    "    \n",
    "    time_column = \"time\"\n",
    "    # Sorting by values of time.        \n",
    "    feature_data = feature_data.sort_values(by=time_column)\n",
    "    feature_data = feature_data.dropna()\n",
    "    train_feature_data = pd.merge_asof(stress_details,\n",
    "                                 feature_data,\n",
    "                                 direction=\"nearest\",\n",
    "                                 by=\"student_id\",\n",
    "                                 on = \"time\",\n",
    "                                 tolerance=pd.Timedelta(\"1 hour\"))\n",
    "    \n",
    "    # Creating New column for activity_details\n",
    "    feature_data[\"stress_level\"] = np.nan \n",
    "    \n",
    "    # Sorting column naming convention\n",
    "    train_col_list = []\n",
    "    \n",
    "    for col in train_feature_data.columns:\n",
    "        if col !=\"stress_level\":\n",
    "            train_col_list.append(col)\n",
    "    \n",
    "    train_col_list.append('stress_level')\n",
    "    train_feature_data = train_feature_data[train_col_list]\n",
    "    train_feature_data = train_feature_data.append(feature_data, ignore_index=True)\n",
    "    train_feature_data.sort_values(by=[\"student_id\",\"time\"], inplace=True)\n",
    "    train_feature_data.drop_duplicates()\n",
    "    train_feature_data.reset_index(inplace=True)\n",
    "    train_feature_x = train_feature_data.iloc[:,1:-1]\n",
    "    train_feature_x = train_feature_x.fillna(method=\"backfill\", axis=0)\n",
    "    train_feature_y = train_feature_data.loc[:,[\"stress_level\"]]\n",
    "    df_filter = train_feature_y.stress_level.notnull()\n",
    "    train_feature_y_indices = train_feature_y[df_filter].index\n",
    "    train_feature_y_indices = pd.DataFrame(train_feature_y_indices)\n",
    "    train_feature_y_indices.rename({0:\"indices\"}, axis=1, inplace=True)\n",
    "#     print(type(train_feature_y_indices))\n",
    "#     display(train_feature_y_indices)\n",
    "#     display(train_feature_x.head())\n",
    "#     display(train_feature_y.head())\n",
    "#     display(train_feature_data.head())    \n",
    "    \n",
    "    \n",
    "    train_feature_x.to_csv(\"data/\"+key+\"_train_x.csv\", index=False)\n",
    "    train_feature_y.to_csv(\"data/\"+key+\"_train_y.csv\", index=False)    \n",
    "    train_feature_y_indices.to_csv(\"data/\"+key+\"_train_y_indices.csv\", index=False)    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
