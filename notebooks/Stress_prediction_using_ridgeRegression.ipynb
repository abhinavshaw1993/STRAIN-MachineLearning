{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run data_getter_and_processor.ipynb\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Obtain Training and testing data.\n",
    "train_x, test_x, train_y, test_y = get_split_train_data(random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    2\n",
       "2    2\n",
       "3    2\n",
       "4    2\n",
       "Name: worst_stress_level, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.1, 'normalize': False} -3.13275942904 Ridge(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "[ 2.9679184   0.93437035  2.09344308  2.0963043   1.6120607   3.11110459\n",
      "  1.66927616  1.42934325  2.54774115  1.91250764  1.51095754  2.2074159\n",
      "  1.30299789  1.48190942  0.8842465   1.35921274  3.28809704  2.06026197\n",
      "  1.216133    1.30367661  1.34861986  0.95247456  1.42956462  1.19321114\n",
      "  1.21022021  2.0144164   1.26137497  1.6391965   2.14453322  1.89720382\n",
      "  2.84229329  1.94615537  1.98715497  2.21215096  2.11746417  1.36722261\n",
      "  1.50228618  1.89629554  2.49372132  1.80713176  1.44196595  2.19456427\n",
      "  1.60086652  1.19914868  1.57965597  1.40333224  1.02878783  1.280647\n",
      "  1.91947418  1.60317008  2.1254349   1.29113542  2.2245023   1.68200515\n",
      "  1.97724616  1.90246788  1.41601123  1.5939767   2.29176614  2.50060329\n",
      "  2.6543492   2.58801066  2.27777282  1.9863463   1.74426227  1.65526794\n",
      "  2.31186502  3.44180548  2.0929764   2.52913171  2.49274057  3.08386166\n",
      "  1.65934388  1.13240291  2.13813231  1.83468909  3.43988364  2.3342043\n",
      "  1.14829869  1.84929069  0.6101305   1.52567492  1.88670589  1.44820266\n",
      "  2.73737739  1.7692381   2.48784658  2.74690057  2.09481541  2.43060626\n",
      "  2.22181915  1.22051633  2.32642313  1.65125433  2.29397829  1.01280914\n",
      "  0.62973208  2.04363979  1.66632149  2.08700832  0.99230085  1.45861787\n",
      "  3.75821518  2.1503404   1.45801477  2.62546507  2.55024175  2.01258512\n",
      "  1.96460354  1.94768613  1.84239784  1.05400884  3.33513915  2.13727125\n",
      "  1.52012344  1.95861583  1.72451082  2.71521635  1.93277394  2.12245533\n",
      "  1.76933435  2.43793549  2.3838855   2.24203173  1.69946081  2.69190092\n",
      "  1.54268191  1.80868222  1.71855777  1.39079257  1.7348659   2.26900366\n",
      "  1.90759314  1.91731764  2.0125047   2.35322588  2.81597084  1.57903822\n",
      "  2.33437537  2.03868634  1.79707613  2.45034811  1.3355833   1.54985569\n",
      "  1.86726328  2.02289211  1.910419    2.90051188  2.25141932  1.74689624\n",
      "  2.55619719  2.16992521  1.57792821  2.5516909   1.73831843  1.3235855\n",
      "  1.8422628   1.85074204  0.65759081  2.12553812  1.81175166  2.99636749\n",
      "  2.2363186   2.39128672  3.36929262  1.82942838  3.08195332  2.56971609\n",
      "  1.69170781  1.73494296  1.46714123  1.97312329  1.59208047  1.85085055\n",
      "  2.47302723  1.02589908  1.22919466  1.24080747  2.59500116  3.3723768\n",
      "  1.5939767   2.08541222  1.76666064  1.30645809  1.55489494  1.7439363\n",
      "  3.22920142  1.97334351  1.57484961  1.87977458  2.91335049  1.80117299\n",
      "  1.64892404  1.50601247  1.55730969  1.43195056  2.38312915  2.02792274\n",
      "  1.76832761  2.54081232  1.86298001  1.70519539  1.98477132  1.87056056\n",
      "  1.58440745  1.26138099  1.86493316  1.90735453  1.2501615   2.22262073\n",
      "  1.63874225  2.22342365  1.28565139  2.39887157  1.48243339  2.11453978\n",
      "  1.4863245   1.55778318  2.17529936  2.18327674  2.39395724  1.89161447\n",
      "  1.57966556  1.79883206  2.3071188   1.25164462  1.89967168  1.90000649\n",
      "  1.87713831  2.68725347  2.52542178  1.73121911  2.52391567  1.49006021\n",
      "  2.16431382  1.72027169  1.23784862  2.00783685  1.89145658  1.94272397\n",
      "  2.20021237  1.86378132  2.122409    1.82121254  1.89021517  1.81033028\n",
      "  1.96082899  1.33836658  1.15156023  1.2553391   1.54690133  2.02563751\n",
      "  2.31600256  2.04797774  2.0916187   2.1895858   1.68862863  1.53347166\n",
      "  2.30924662  1.87881127  1.35801411  2.58783621  2.30073778  1.50819879\n",
      "  1.15693091  1.45236713  1.93127862  1.91000663  1.25778576  2.14470042\n",
      "  2.99895345  2.78303699  2.0534588   1.72295606  1.76382017  1.76054344\n",
      "  1.56366883  2.08629106  2.0666669   2.4957309   2.80203082  1.31001093\n",
      "  1.79035791  1.81533742  2.68984471  2.38011688  1.79475352  1.97681462\n",
      "  2.15558145  1.93000026  2.69944965  1.9183606   2.36538307  1.90244587\n",
      "  2.06735192  1.85918189  1.52465113  3.09870915  1.96464231  2.19840204\n",
      "  2.14030112  2.24936131  2.5643138   1.93907454  2.8706274   1.58589188\n",
      "  1.48690819  1.8920241   2.39862414  1.43222926  1.45527754  1.47673403\n",
      "  1.48050977  1.76322852  1.71958996  1.64340937  2.28769075  2.5251809\n",
      "  1.7851559   1.40673199  2.64908144  2.81016495  1.73363726  2.07517124\n",
      "  2.60162843  1.7132654   1.85054233  1.84105954  2.5916215   1.87387833\n",
      "  1.7789842   2.72299607  1.37731818  1.95195169  2.66989407  1.35971855\n",
      "  2.68817493  1.97872223  2.43255878  1.42320379  2.64738764  1.55975253\n",
      "  2.45278385  1.77700241  2.27050564  2.00217025  2.38175133  2.13747304\n",
      "  1.93669304  2.43163007  2.13862175  3.11096226  1.98168213  1.80402905\n",
      "  2.9688874   1.39409489  2.41748159  2.48279369  0.94763606  1.78970177\n",
      "  2.80697598  2.66106175  1.69365443  2.6047482   1.33801215  1.35984299\n",
      "  2.39806578  2.39818844  1.88162994  2.20089132  2.1423467   1.1047233\n",
      "  1.84655948  1.73098538  2.1415777   2.57766304  3.84591869  2.75646132\n",
      "  1.76647769  2.40636069  3.56220092  1.85679466  1.61320851  2.62505749\n",
      "  2.20363902  1.57992545  2.41349038  2.00889837]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "# Apply gridSearch to search best Random Forest model for imbalanced data for worst\n",
    "worst_stress_levels = train_y.loc[:,\"worst_stress_level\"]\n",
    "ballanced_train_x, worst_stress_levels = balance_data(train_x, worst_stress_levels) \n",
    "# ballanced_train_x = scale(ballanced_train_x)\n",
    "\n",
    "param_grid = [\n",
    "    {'alpha': [10e-3, 10e-4, 10e-5, 10e-2, 10e-1, 1, 10],\n",
    "    'normalize': [False]}\n",
    " ]\n",
    "\n",
    "# display(worst_stress_levels.head())\n",
    "# print(worst_stress_levels.columns.values)\n",
    "\n",
    "clf = GridSearchCV(Ridge(), param_grid, cv=5, scoring=\"neg_mean_squared_error\", n_jobs=-1)\n",
    "clf.fit(ballanced_train_x, worst_stress_levels)\n",
    "print(clf.best_params_, clf.best_score_, clf.best_estimator_)\n",
    "\n",
    "# predicting only worst stress levels.\n",
    "estimator = clf.estimator\n",
    "estimator.fit(ballanced_train_x, worst_stress_levels)\n",
    "pred_worst_stress_levels = estimator.predict(test_x)\n",
    "\n",
    "print(pred_worst_stress_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst stress levels accuracy is 35.3092783505 %\n"
     ]
    }
   ],
   "source": [
    "# Scoring the metrics.\n",
    "\n",
    "score = accuracy_score(test_y.loc[:,\"worst_stress_level\"], np.round(pred_worst_stress_levels), normalize=True)\n",
    "print(\"Worst stress levels accuracy is \"+ str(score * 100) + \" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2_error is :  1.26038273656\n",
      "l1_error is :  0.906369423527\n"
     ]
    }
   ],
   "source": [
    "# Finding L2 error with the predicted data.\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "l2_error = mean_squared_error(y_pred=pred_worst_stress_levels, y_true=test_y.loc[:,\"worst_stress_level\"])\n",
    "l1_error = mean_absolute_error(y_pred=pred_worst_stress_levels, y_true=test_y.loc[:,\"worst_stress_level\"])\n",
    "\n",
    "print(\"L2_error is : \", l2_error)\n",
    "print(\"l1_error is : \", l1_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
