{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from IPython.display import display\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "def generate_baseline_variables(feature_list=[\n",
    "    \"activity_details\",\n",
    "    # \"dinning_details\" ,\n",
    "    \"sms_details\",\n",
    "    \"audio_details\",\n",
    "    \"conversation_details\",\n",
    "    \"dark_details\",\n",
    "    \"phonecharge_details\",\n",
    "    \"phonelock_details\",\n",
    "    \"gps_details\"],\n",
    "    val_set_size = .3,\n",
    "    restrict_seqlen=10,\n",
    "    is_cuda_available=False\n",
    "                               \n",
    "                               ):\n",
    "    \n",
    "    # Dict Initialization.\n",
    "    train_feature_dict = {}\n",
    "    val_feature_dict = {}\n",
    "    train_x_list = []\n",
    "    val_x_list = []\n",
    "    for feature in feature_list:\n",
    "\n",
    "        # Read CSV and skip the time columns.\n",
    "        raw_feature_train_x = pd.read_csv(\"Data/\"+feature+\"_train_x.csv\", skip_blank_lines=False).iloc[:,1:]\n",
    "        raw_feature_train_y = pd.read_csv(\"Data/\"+feature+\"_train_y.csv\", skip_blank_lines=False)\n",
    "        # to bring the values from 0-4.\n",
    "        raw_feature_train_y[\"stress_level\"] += -1\n",
    "        raw_feature_train_y_indices = pd.read_csv(\"Data/\"+feature+\"_train_y_indices.csv\", skip_blank_lines=False)\n",
    "\n",
    "        # Finding Last Valid index.\n",
    "        last_valid_index = raw_feature_train_y_indices.iloc[-1,:].values\n",
    "        last_valid_index = int(last_valid_index)\n",
    "\n",
    "        #Truncating the raw_x features for which y values do not exist.\n",
    "        raw_feature_train_x = raw_feature_train_x.iloc[:last_valid_index+1,:]\n",
    "\n",
    "        # Hardcore indexing, to convert single index to multi so that max, min and avg can be taken easily.\n",
    "        # Train set.\n",
    "        list_a = []\n",
    "        list_b = raw_feature_train_x.index.values    \n",
    "        feature_indices_list = raw_feature_train_y_indices['indices'].values\n",
    "\n",
    "        for idx in feature_indices_list:\n",
    "            if len(list_a) == 0:\n",
    "                list_a += [idx for k in range(0,idx+1)]\n",
    "            else:\n",
    "                list_a += [idx for k in range(len(list_a)-1,idx)]\n",
    "\n",
    "\n",
    "        index_keys = [\n",
    "            np.array(list_a),\n",
    "            np.array(list_b)        \n",
    "        ]\n",
    "\n",
    "\n",
    "        raw_feature_train_x.set_index(keys=index_keys, inplace=True)\n",
    "\n",
    "        # Colapsing Multindex to fin min, max and mean of the seq. \n",
    "        raw_feature_train_x_min = raw_feature_train_x.min(level=0)\n",
    "        raw_feature_train_x_max = raw_feature_train_x.max(level=0)\n",
    "        raw_feature_train_x_mean = raw_feature_train_x.mean(level=0)\n",
    "\n",
    "        raw_feature_train_x = pd.concat([raw_feature_train_x_min, \n",
    "                                         raw_feature_train_x_max.iloc[:,1:], \n",
    "                                         raw_feature_train_x_mean.iloc[:,1:]],\n",
    "                                         axis=1,\n",
    "                                         ignore_index=True)\n",
    "\n",
    "\n",
    "        # splitting data into test and train splits. Keeping 30% of labels for Val.\n",
    "        total_y_labels = len(raw_feature_train_y_indices)\n",
    "        val_samples = total_y_labels * val_set_size\n",
    "        val_samples = math.floor(val_samples)\n",
    "\n",
    "\n",
    "        # Selecting new subset of data.\n",
    "        feature_train_x = raw_feature_train_x.iloc[:total_y_labels-val_samples+1]\n",
    "        feature_train_y = raw_feature_train_y.dropna().iloc[:total_y_labels-val_samples+1]\n",
    "\n",
    "        feature_val_x = raw_feature_train_x.iloc[total_y_labels-val_samples+1:]\n",
    "        feature_val_y = raw_feature_train_y.dropna().iloc[total_y_labels-val_samples+1:]\n",
    "        \n",
    "        train_x_list.append(feature_train_x)\n",
    "        val_x_list.append(feature_val_x)\n",
    "    \n",
    "    # removing extra student_id columns.\n",
    "    # train\n",
    "    first_feature = train_x_list[0]\n",
    "    student_id_col = first_feature.iloc[:,0]\n",
    "    final_list = [feature.iloc[:,1:]  for feature in train_x_list]\n",
    "    final_list.insert(0, student_id_col)\n",
    "    train_x = pd.concat(final_list, axis=1,ignore_index=True)\n",
    "    \n",
    "    # val\n",
    "    first_feature = val_x_list[0]\n",
    "    student_id_col = first_feature.iloc[:,0]\n",
    "    final_list =  [ feature.iloc[:,1:]  for feature in val_x_list]\n",
    "    final_list.insert(0, student_id_col)\n",
    "    val_x = pd.concat(final_list, axis=1, ignore_index=True)\n",
    "    \n",
    "    train_target = feature_train_y\n",
    "    val_target = feature_val_y\n",
    "    \n",
    "    np_train_x = train_x.as_matrix()\n",
    "    np_val_x = val_x.as_matrix()\n",
    "    np_train_target = train_target.as_matrix()\n",
    "    np_val_target = val_target.as_matrix()\n",
    "    \n",
    "    tensor_train_x = torch.from_numpy(np_train_x)\n",
    "    tensor_val_x = torch.from_numpy(np_val_x) \n",
    "    tensor_train_target = torch.from_numpy(np_train_target)\n",
    "    tensor_val_target = torch.from_numpy(np_val_target)\n",
    "    \n",
    "    if is_cuda_available:\n",
    "        tensor_train_x = tensor_train_x.cuda()\n",
    "        tensor_val_x = tensor_val_x.cuda()\n",
    "        tensor_train_target = tensor_train_target.cuda()\n",
    "        tensor_val_target = tensor_val_target.cuda()\n",
    "\n",
    "    train_input_seq = Variable(tensor_train_x ,requires_grad=False).float()\n",
    "    train_target = Variable(tensor_train_target ,requires_grad=False).long()\n",
    "    val_input_seq = Variable(tensor_val_x ,requires_grad=False).float()\n",
    "    val_target = Variable(tensor_val_target ,requires_grad=False).long()\n",
    "    \n",
    "    return train_input_seq, train_target, val_input_seq, val_target\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1.0000  0.0000  0.0000  0.0000\n",
      " 1.0000  0.0000  0.0000  0.0000\n",
      " 1.0000  0.0000  0.0000  0.0000\n",
      " 1.0000  0.0000  0.0000  0.0000\n",
      " 1.0000  0.0000  3.0000  0.0120\n",
      " 1.0000  0.0000  3.0000  0.1290\n",
      " 1.0000  0.0000  3.0000  0.2176\n",
      " 1.0000  0.0000  3.0000  0.2407\n",
      " 1.0000  0.0000  3.0000  0.1120\n",
      " 1.0000  0.0000  3.0000  0.0306\n",
      " 1.0000  0.0000  3.0000  0.1028\n",
      " 1.0000  0.0000  3.0000  0.1356\n",
      " 1.0000  0.0000  3.0000  0.1108\n",
      " 1.0000  0.0000  3.0000  0.1737\n",
      " 1.0000  0.0000  3.0000  0.1402\n",
      " 1.0000  0.0000  3.0000  0.1035\n",
      " 1.0000  0.0000  3.0000  0.1098\n",
      " 1.0000  0.0000  3.0000  0.1633\n",
      " 1.0000  0.0000  3.0000  0.0547\n",
      " 1.0000  0.0000  3.0000  0.0876\n",
      " 1.0000  0.0000  3.0000  0.0422\n",
      " 1.0000  0.0000  3.0000  0.0851\n",
      " 1.0000  0.0000  3.0000  0.1346\n",
      " 1.0000  0.0000  3.0000  0.0460\n",
      " 1.0000  0.0000  3.0000  0.0923\n",
      " 1.0000  0.0000  3.0000  0.0323\n",
      " 1.0000  0.0000  3.0000  0.0743\n",
      "[torch.FloatTensor of size 27x4]\n",
      " Variable containing:\n",
      "    0\n",
      "    2\n",
      "    3\n",
      "    2\n",
      "    3\n",
      "    3\n",
      "    0\n",
      "    4\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    3\n",
      "    3\n",
      "    3\n",
      "    4\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    3\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "[torch.LongTensor of size 27x1]\n",
      " Variable containing:\n",
      " 1.0000  0.0000  3.0000  0.1767\n",
      " 1.0000  0.0000  3.0000  0.1507\n",
      " 1.0000  0.0000  3.0000  0.1012\n",
      " 1.0000  0.0000  3.0000  0.2496\n",
      " 1.0000  0.0000  3.0000  0.0305\n",
      " 1.0000  0.0000  0.0000  0.0000\n",
      " 1.0000  0.0000  3.0000  0.0085\n",
      " 1.0000  0.0000  3.0000  0.0988\n",
      " 1.0000  0.0000  3.0000  0.1110\n",
      "[torch.FloatTensor of size 9x4]\n",
      " Variable containing:\n",
      "    3\n",
      "    3\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    2\n",
      "    1\n",
      "    0\n",
      "[torch.LongTensor of size 9x1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_list=[\"activity_details\"]\n",
    "train_input_seq, train_target, val_input_seq, val_target = generate_baseline_variables(feature_list)\n",
    "\n",
    "print (train_input_seq, train_target, val_input_seq, val_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
