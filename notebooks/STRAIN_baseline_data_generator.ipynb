{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from IPython.display import display\n",
    "import math\n",
    "\n",
    "def generate_baseline_variables(feature_list=[\n",
    "    \"activity_details\",\n",
    "    # \"dinning_details\" ,\n",
    "    \"sms_details\",\n",
    "    \"audio_details\",\n",
    "    \"conversation_details\",\n",
    "    \"dark_details\",\n",
    "    \"phonecharge_details\",\n",
    "    \"phonelock_details\",\n",
    "    \"gps_details\"],\n",
    "    val_set_size = .3,\n",
    "    restrict_seqlen=10,\n",
    "    is_cuda_available=False):\n",
    "\n",
    "    # Dict Initialization.\n",
    "    train_feature_dict = {}\n",
    "    val_feature_dict = {}\n",
    "\n",
    "    for feature in feature_list:\n",
    "\n",
    "        # Read CSV and skip the time columns.\n",
    "        raw_feature_train_x = pd.read_csv(\"Data/\"+feature+\"_train_x.csv\", skip_blank_lines=False).iloc[:,1:]\n",
    "        raw_feature_train_y = pd.read_csv(\"Data/\"+feature+\"_train_y.csv\", skip_blank_lines=False)\n",
    "        # to bring the values from 0-4.\n",
    "        raw_feature_train_y[\"stress_level\"] += -1\n",
    "        raw_feature_train_y_indices = pd.read_csv(\"Data/\"+feature+\"_train_y_indices.csv\", skip_blank_lines=False)\n",
    "\n",
    "        # Finding Last Valid index.\n",
    "        last_valid_index = raw_feature_train_y_indices.iloc[-1,:].values\n",
    "        last_valid_index = int(last_valid_index)\n",
    "\n",
    "        #Truncating the raw_x features for which y values do not exist.\n",
    "        raw_feature_train_x = raw_feature_train_x.iloc[:last_valid_index+1,:]\n",
    "\n",
    "        # Hardcore indexing, to convert single index to multi so that max, min and avg can be taken easily.\n",
    "        # Train set.\n",
    "        list_a = []\n",
    "        list_b = raw_feature_train_x.index.values    \n",
    "        feature_indices_list = raw_feature_train_y_indices['indices'].values\n",
    "\n",
    "        for idx in feature_indices_list:\n",
    "            if len(list_a) == 0:\n",
    "                list_a += [idx for k in range(0,idx+1)]\n",
    "            else:\n",
    "                list_a += [idx for k in range(len(list_a)-1,idx)]\n",
    "\n",
    "\n",
    "        index_keys = [\n",
    "            np.array(list_a),\n",
    "            np.array(list_b)        \n",
    "        ]\n",
    "\n",
    "\n",
    "        raw_feature_train_x.set_index(keys=index_keys, inplace=True)\n",
    "\n",
    "        # Colapsing Multindex to fin min, max and mean of the seq. \n",
    "        raw_feature_train_x_min = raw_feature_train_x.min(level=0)\n",
    "        raw_feature_train_x_max = raw_feature_train_x.max(level=0)\n",
    "        raw_feature_train_x_mean = raw_feature_train_x.mean(level=0)\n",
    "\n",
    "        raw_feature_train_x = pd.concat([raw_feature_train_x_min, \n",
    "                                         raw_feature_train_x_max.iloc[:,1:], \n",
    "                                         raw_feature_train_x_mean.iloc[:,1:]],\n",
    "                                         axis=1,\n",
    "                                         ignore_index=True)\n",
    "\n",
    "\n",
    "        # splitting data into test and train splits. Keeping 30% of labels for Val.\n",
    "        total_y_labels = len(raw_feature_train_y_indices)\n",
    "        val_samples = total_y_labels * val_set_size\n",
    "        val_samples = math.floor(val_samples)\n",
    "\n",
    "\n",
    "        # Selecting new subset of data.\n",
    "        feature_train_x = raw_feature_train_x.iloc[:total_y_labels-val_samples+1]\n",
    "        feature_train_y = raw_feature_train_y.dropna().iloc[:total_y_labels-val_samples+1]\n",
    "\n",
    "        feature_val_x = raw_feature_train_x.iloc[total_y_labels-val_samples+1:]\n",
    "        feature_val_y = raw_feature_train_y.iloc[total_y_labels-val_samples+1:]\n",
    "\n",
    "        # Finding Indexes for the target outputs. Then we convert it into into a tensor.\n",
    "        # Converting to numpy array.\n",
    "        np_feature_train_x = feature_train_x.as_matrix()\n",
    "        np_feature_train_y = feature_train_y.as_matrix()\n",
    "\n",
    "        np_feature_val_x = feature_val_x.as_matrix()\n",
    "        np_feature_val_y = feature_val_y.as_matrix()\n",
    "\n",
    "        # Extracting shape for reshaping.\n",
    "        x, y = np_feature_train_x.shape\n",
    "        shape = (x, 1, y)\n",
    "        np_feature_train_x = np_feature_train_x.reshape(shape)\n",
    "\n",
    "        # Validation set.\n",
    "        x, y = np_feature_val_x.shape\n",
    "        shape = (x, 1, y)\n",
    "        np_feature_val_x = np_feature_val_x.reshape(shape)\n",
    "\n",
    "        tensor_feature_train_x = torch.from_numpy(np_feature_train_x)\n",
    "        tensor_feature_train_y = torch.from_numpy(np_feature_train_y)\n",
    "\n",
    "        tensor_feature_val_x = torch.from_numpy(np_feature_val_x)\n",
    "        tensor_feature_val_y = torch.from_numpy(np_feature_val_y)\n",
    "\n",
    "        if is_cuda_available:\n",
    "            tensor_feature_train_x = tensor_feature_train_x.cuda()\n",
    "            tensor_feature_train_y = tensor_feature_train_y.cuda()\n",
    "            tensor_feature_val_x = tensor_feature_val_x.cuda()\n",
    "            tensor_feature_val_y = ttensor_feature_val_y.cuda()\n",
    "\n",
    "        train_input_seq = Variable(tensor_feature_train_x, requires_grad=False).float()\n",
    "        train_target = Variable(tensor_feature_train_y, requires_grad=False).long()\n",
    "\n",
    "        val_input_seq = Variable(tensor_feature_val_x, requires_grad=False).float()\n",
    "        val_target = Variable(tensor_feature_val_y, requires_grad=False).long()\n",
    "\n",
    "        train_feature_dict[feature] = (train_input_seq, train_target)\n",
    "        val_feature_dict[feature] = (val_input_seq, val_target)\n",
    "        \n",
    "    return train_feature_dict, val_feature_dict\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
