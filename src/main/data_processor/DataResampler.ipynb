{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from datetime import timedelta\n",
    "from datetime import date as convert_to_date\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "ROOT_DIR= os.getcwd()\n",
    "data_dir = ROOT_DIR + \"/StudentLife Data\"\n",
    "student_list = os.listdir(data_dir)\n",
    "\n",
    "student_list = [ _ for _ in student_list if \"student\" in _]\n",
    "\n",
    "def adjust_stress_values(stress_level):\n",
    "    mapping = {\n",
    "        1: 2,\n",
    "        2: 3,\n",
    "        3: 4,\n",
    "        4: 1,\n",
    "        5: 0\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        return mapping[stress_level]\n",
    "    except KeyError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhinav/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2910: FutureWarning: to_datetime is deprecated. Use self.to_pydatetime()\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student 0\n",
      "student 1\n",
      "student 10\n",
      "student 12\n",
      "student 14\n",
      "student 15\n",
      "student 16\n",
      "student 17\n",
      "student 18\n",
      "student 19\n",
      "student 2\n",
      "student 20\n",
      "student 22\n",
      "student 23\n",
      "student 24\n",
      "student 25\n",
      "student 27\n",
      "student 3\n",
      "student 30\n",
      "student 32\n",
      "student 33\n",
      "student 34\n",
      "student 35\n",
      "student 36\n",
      "student 39\n",
      "student 4\n",
      "student 41\n",
      "student 42\n",
      "student 43\n",
      "student 44\n",
      "student 45\n",
      "student 46\n",
      "student 47\n",
      "student 49\n",
      "student 5\n",
      "student 50\n",
      "student 51\n",
      "student 52\n",
      "student 53\n",
      "student 54\n",
      "student 56\n",
      "student 57\n",
      "student 58\n",
      "student 59\n",
      "student 7\n",
      "student 8\n",
      "student 9\n"
     ]
    }
   ],
   "source": [
    "for student in student_list:\n",
    "    print(student)\n",
    "\n",
    "    files = os.listdir(data_dir + \"/{}\".format(student))\n",
    "    files = [ _ for _ in files if \"train_x.csv\" in _]\n",
    "    \n",
    "    for file in files:\n",
    "        \n",
    "\n",
    "        \n",
    "        csv_file_name = \"{}/{}/{}\".format(data_dir, student, file)\n",
    "        \n",
    "        feature_train_x = pd.read_csv(\"{}/{}/{}\".format(data_dir, student, file),\n",
    "                                      skip_blank_lines=False, \n",
    "                                      parse_dates= True,\n",
    "                                      index_col=1\n",
    "                                     )\n",
    "        feature_train_x = feature_train_x.iloc[:,1:]\n",
    "        resampled_feature_train_x = feature_train_x.resample('2T').max()\n",
    "        resampled_feature_train_x.iloc[:, :-1] = resampled_feature_train_x.iloc[:, :-1].fillna(method=\"ffill\")\n",
    "        \n",
    "        \n",
    "        # Parse Min and Max Date, Convert them to string.\n",
    "        start_date = resampled_feature_train_x.index.min()\n",
    "        end_date = resampled_feature_train_x.index.max()\n",
    "        start_date = start_date.to_datetime()\n",
    "        end_date = end_date.to_datetime()\n",
    "        \n",
    "        start_date = convert_to_date(start_date.year, start_date.month, start_date.day)\n",
    "        end_date = convert_to_date(end_date.year, end_date.month, end_date.day) + timedelta(days=1)\n",
    "        \n",
    "        ix = pd.date_range(start=start_date, end=end_date, freq='2T')\n",
    "        resampled_feature_train_x = resampled_feature_train_x.reindex(ix).iloc[:-1,1:]\n",
    "        \n",
    "        # Filling NA Values.\n",
    "        resampled_feature_train_x.iloc[:, :-1] = resampled_feature_train_x.iloc[:, :-1].fillna(method='ffill')\n",
    "        resampled_feature_train_x.iloc[:, :-1] = resampled_feature_train_x.iloc[:, :-1].fillna(method='bfill')\n",
    "        \n",
    "        unique_dates = list(resampled_feature_train_x.index.map(lambda t: t.date()).unique())\n",
    "        \n",
    "        x = []\n",
    "        mask = []\n",
    "        y = []\n",
    "        \n",
    "        for idx, date in enumerate(unique_dates):\n",
    "            \n",
    "            days_train_x = resampled_feature_train_x.loc[str(date) : str(date)].iloc[:, :-1]\n",
    "            days_train_y = resampled_feature_train_x.loc[str(date) : str(date)].iloc[:, -1]\n",
    "            days_train_y = days_train_y.apply(adjust_stress_values)\n",
    "            \n",
    "            days_train_y.reset_index(drop=True, inplace=True)\n",
    "            days_train_y_index_mask = days_train_y.notnull()\n",
    "            days_train_y = days_train_y[days_train_y_index_mask]\n",
    "            \n",
    "            days_train_x = days_train_x.as_matrix()\n",
    "            days_train_y_index_mask = days_train_y_index_mask.as_matrix()\n",
    "#             print(\"Mask Shape:\", days_train_y_index_mask.shape)\n",
    "            \n",
    "            #Normalize Days Training Data\n",
    "            days_train_x = normalize(days_train_x)\n",
    "            \n",
    "            x.append(days_train_x)\n",
    "            mask.append(days_train_y_index_mask)\n",
    "            \n",
    "            y = y + list(days_train_y)\n",
    "        \n",
    "        # Stacking All the days worth data.\n",
    "        train_x = np.stack(x, axis=0)\n",
    "        train_mask = np.stack(mask, axis=0)\n",
    "        train_mask = train_mask.astype(int)\n",
    "        train_y = np.array(y)\n",
    "        \n",
    "#         print(\"TrainX shape {}, Mask Shape {}\".format(train_x.shape, train_mask.shape))\n",
    "        \n",
    "        np.savez(\"{}/{}/{}\".format(data_dir, student, file[:-4]), input_seq=train_x, mask=train_mask, target=train_y )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-1.5198\n",
      " 0.7118\n",
      "-0.9143\n",
      "-0.8680\n",
      "-1.6288\n",
      " 0.9820\n",
      "-0.4699\n",
      " 0.7407\n",
      " 1.2879\n",
      " 1.8683\n",
      "[torch.FloatTensor of size 10]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.randn( 2, 3, 5)\n",
    "mask = torch.ByteTensor([[1, 0, 0], [0,1,0]])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mask = torch.unsqueeze(mask, dim=2)\n",
    "mask = mask.expand(2,3,5)\n",
    "print(torch.masked_select(a, mask))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
